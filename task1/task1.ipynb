{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing all the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install re\n",
    "!pip install requests\n",
    "!pip install io\n",
    "!pip install torch\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install transformers\n",
    "!pip install torchvision\n",
    "!pip install PIL\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import ViTModel,ViTImageProcessor\n",
    "from PIL import Image \n",
    "import torchvision.transforms as transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:02:22.673366Z",
     "iopub.status.busy": "2023-12-13T08:02:22.672944Z",
     "iopub.status.idle": "2023-12-13T08:02:22.680978Z",
     "shell.execute_reply": "2023-12-13T08:02:22.679479Z",
     "shell.execute_reply.started": "2023-12-13T08:02:22.673331Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class initialization of model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:03:18.738601Z",
     "iopub.status.busy": "2023-12-13T08:03:18.738172Z",
     "iopub.status.idle": "2023-12-13T08:03:18.758518Z",
     "shell.execute_reply": "2023-12-13T08:03:18.756777Z",
     "shell.execute_reply.started": "2023-12-13T08:03:18.738568Z"
    }
   },
   "outputs": [],
   "source": [
    "class transformermodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(transformermodel, self).__init__()\n",
    "        self.base_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        self.base_model_1 = AutoModel.from_pretrained('vinai/bertweet-base')\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.base_model_1.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.img_enc1 = nn.TransformerEncoderLayer(768, 8, activation='gelu', batch_first=True)\n",
    "        self.txt_enc1 = nn.TransformerEncoderLayer(768, 8, activation='gelu', batch_first=True)\n",
    "        self.txt_enc2 = nn.TransformerEncoderLayer(768, 12, activation='gelu', batch_first=True)\n",
    "        self.img_enc2 = nn.TransformerEncoderLayer(768, 12, activation='gelu', batch_first=True)\n",
    "        self.txt_enc3 = nn.TransformerEncoderLayer(768, 12, activation='gelu', batch_first=True)\n",
    "        self.img_enc3 = nn.TransformerEncoderLayer(768, 12, activation='gelu', batch_first=True)\n",
    "        self.img_dec1 = nn.TransformerDecoderLayer(768, 12, activation='gelu', batch_first=True)\n",
    "        self.txt_dec1 = nn.TransformerDecoderLayer(768, 12, activation='gelu', batch_first=True)\n",
    "        self.txt_dec2 = nn.TransformerDecoderLayer(768, 8, activation='gelu', batch_first=True)\n",
    "        self.img_dec2 = nn.TransformerDecoderLayer(768, 8, activation='gelu', batch_first=True)\n",
    "        self.img_dec3 = nn.TransformerDecoderLayer(768, 12, activation='gelu', batch_first=True)\n",
    "        self.txt_dec3 = nn.TransformerDecoderLayer(768, 12, activation='gelu', batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(768, 768)\n",
    "        self.fc1 = nn.Linear(768, 768)\n",
    "        self.fc2 = nn.Linear(768, 768)\n",
    "        self.fc3 = nn.Linear(768, 768)\n",
    "        self.corr1 = nn.Linear(768, 256)\n",
    "        self.corr1_1 = nn.Linear(256, 64)\n",
    "        self.corr2 = nn.Linear(768, 256)\n",
    "        self.corr2_1 = nn.Linear(256, 64)\n",
    "        self.img = nn.Linear(768, 256)\n",
    "        self.img_1 = nn.Linear(256, 64)\n",
    "        self.txt = nn.Linear(768, 256)\n",
    "        self.txt_1 = nn.Linear(256, 64)\n",
    "        self.FC = nn.Linear(64 * 4 + 5, 128)\n",
    "        self.FC1 = nn.Linear(128, 64)\n",
    "        self.FC2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, txt, mask, img, followers,time, is_photo, is_gif, is_video):\n",
    "        txt_output = self.base_model_1(txt, attention_mask=mask)\n",
    "        img_output = self.base_model(img)\n",
    "        img_output['last_hidden_state'] = (self.img_enc1(img_output['last_hidden_state']))\n",
    "        txt_output['last_hidden_state'] = (self.txt_enc1(txt_output['last_hidden_state']))\n",
    "        cross_attention_img = self.img_dec1(img_output['last_hidden_state'], txt_output['last_hidden_state'])\n",
    "        cross_attention_txt = self.txt_dec1(txt_output['last_hidden_state'], img_output['last_hidden_state'])\n",
    "        cross_attention_img = (self.img_enc2(cross_attention_img))\n",
    "        cross_attention_txt = (self.txt_enc2(cross_attention_txt))\n",
    "        cross_attention_img1 = ((self.img_dec2(cross_attention_img, txt_output['last_hidden_state'])))\n",
    "        cross_attention_txt1 = ((self.txt_dec2(cross_attention_txt, img_output['last_hidden_state'])))\n",
    "        cross_attention_img1 = (self.img_enc3(cross_attention_img1))\n",
    "        cross_attention_txt1 = (self.txt_enc3(cross_attention_txt1))\n",
    "        cross_attention_img2 = (self.img_dec3(cross_attention_img1, txt_output['last_hidden_state']))\n",
    "        cross_attention_txt2 = (self.txt_dec3(cross_attention_txt1, img_output['last_hidden_state']))\n",
    "        corr1 = F.gelu(self.fc(cross_attention_img2[:, 0, :]))\n",
    "        corr2 = F.gelu(self.fc1(cross_attention_txt2[:, 0, :]))\n",
    "        corr1 = F.gelu((self.corr1_1(F.elu((self.corr1(corr1))))))\n",
    "        corr2 = F.gelu((self.corr2_1(F.elu((self.corr2(corr2))))))\n",
    "        img_out = img_output['pooler_output']\n",
    "        txt_out = txt_output['pooler_output']\n",
    "        img_out = F.gelu((self.img_1(F.elu((self.img(img_out))))))\n",
    "        txt_out = F.gelu((self.txt_1(F.elu((self.txt(txt_out))))))\n",
    "        pooler_output = (torch.cat([corr1, corr2, img_out, txt_out, followers, is_photo, is_gif, is_video, time], dim=1))\n",
    "        pooler_output = (F.gelu((self.FC1(F.leaky_relu((self.FC(pooler_output)))))))\n",
    "        return torch.squeeze(self.FC2(pooler_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model\n",
    "Replace '/path/to/your/models/model.pth' with the actual path for your model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:03:19.100859Z",
     "iopub.status.busy": "2023-12-13T08:03:19.100459Z",
     "iopub.status.idle": "2023-12-13T08:03:28.172529Z",
     "shell.execute_reply": "2023-12-13T08:03:28.170878Z",
     "shell.execute_reply.started": "2023-12-13T08:03:19.100827Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load('/kaggle/input/final-model/final.pth', map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to remove emojis or others special characters excluding punctuation marks from the tweet text\n",
    "The Bertweet model tokenizer is not able to tokenize special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               u\"\\U000024C2-\"  # Exclude '#' from removal\n",
    "                               u\"\\U0001F251\"  # Exclude '#' from removal\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text_no_emojis = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove special characters, keeping digits, '#' and basic punctuation marks\n",
    "    text_no_special_chars = re.sub(r'[^\\w\\s\\d#.,!?;:()\\'\"]', '', text_no_emojis)\n",
    "\n",
    "    # Split the text into words\n",
    "    words = text_no_special_chars.split()\n",
    "\n",
    "    # Concatenate words into a single string with space-separated words\n",
    "    concatenated_string = ' '.join(words)\n",
    "\n",
    "    return concatenated_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:03:31.807844Z",
     "iopub.status.busy": "2023-12-13T08:03:31.807451Z",
     "iopub.status.idle": "2023-12-13T08:03:31.826677Z",
     "shell.execute_reply": "2023-12-13T08:03:31.825423Z",
     "shell.execute_reply.started": "2023-12-13T08:03:31.807803Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, annotations_file):\n",
    "        ds = pd.read_excel(annotations_file)\n",
    "        self.dates = pd.to_datetime(ds['date'])\n",
    "        curr = pd.Timestamp('2023-12-05 12:00:00')\n",
    "        self.pattern =  r'https[^\\' ]*\\''\n",
    "        self.dates = ((curr - self.dates).dt.total_seconds() / (24 * 3600))\n",
    "        self.texts = [preprocess(text) for text in ds['content']]\n",
    "        self.followers = torch.tensor(ds['followers'], dtype=torch.float)\n",
    "        self.labels = torch.tensor(ds['likes'], dtype=torch.float)\n",
    "        self.media = ds['media']\n",
    "        self.id = ds['id']\n",
    "        self.is_photo = torch.tensor(ds['media'].apply(lambda x: 1 if len(x) >= 2 and x[1] == 'P' else 0), dtype=torch.float)\n",
    "        self.is_video = torch.tensor(ds['media'].apply(lambda x: 1 if len(x) >= 2 and x[1] == 'V' else 0), dtype=torch.float)\n",
    "        self.is_gif = torch.tensor(ds['media'].apply(lambda x: 1 if len(x) >= 2 and x[1] == 'G' else 0), dtype=torch.float)\n",
    "        self.img_processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "        self.txt_tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
    "\n",
    "        # Tokenize all texts during initialization\n",
    "        self.tokenized_texts = self.txt_tokenizer(self.texts, return_tensors=\"pt\", padding=\"max_length\", truncation=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        followers = self.followers[index]\n",
    "        label = self.labels[index]\n",
    "        is_photo = self.is_photo[index]\n",
    "        is_video = self.is_video[index]\n",
    "        is_gif = self.is_gif[index]\n",
    "        url = re.search(self.pattern, self.media[index])\n",
    "        try:\n",
    "            response = requests.get(url[0][0:-1])\n",
    "            if response.status_code == 200:\n",
    "                image = Image.open(BytesIO(response.content))\n",
    "                if image.mode == 'RGBA':\n",
    "                    image = image.convert('RGB')\n",
    "                img_tensor = torch.tensor(self.img_processor(image)['pixel_values'][0], dtype=torch.float)\n",
    "            else:\n",
    "                img_tensor = torch.zeros(3, 224, 224)\n",
    "        except Exception as e:\n",
    "            img_tensor = torch.zeros(3, 224, 224)\n",
    "        time = torch.tensor(self.dates[index], dtype=torch.float)\n",
    "\n",
    "        # Access input_ids and attention_mask from tokenized_texts\n",
    "        input_ids = self.tokenized_texts['input_ids'][index]\n",
    "        attention_mask = self.tokenized_texts['attention_mask'][index]\n",
    "\n",
    "        sample = {\n",
    "            \"Text\": {\n",
    "                \"input_ids\": input_ids,\n",
    "                \"attention_mask\": attention_mask,\n",
    "            },\n",
    "            \"followers\": torch.unsqueeze(followers,0),\n",
    "            \"img\": img_tensor,\n",
    "            \"likes\": label,\n",
    "            \"time\": torch.unsqueeze(time,0),\n",
    "            \"is_photo\" : torch.unsqueeze(is_photo,0),\n",
    "            \"is_video\" : torch.unsqueeze(is_video,0),\n",
    "            \"is_gif\" : torch.unsqueeze(is_gif,0),\n",
    "            \"id\" : self.id[index],\n",
    "        }\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an instance of the dataset\n",
    "Replace '/kaggle/input/dataset/PS_8_dataset_with_followers.xlsx' with the actual path for your dataset excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:03:32.175082Z",
     "iopub.status.busy": "2023-12-13T08:03:32.174671Z",
     "iopub.status.idle": "2023-12-13T08:06:02.175211Z",
     "shell.execute_reply": "2023-12-13T08:06:02.174127Z",
     "shell.execute_reply.started": "2023-12-13T08:03:32.175048Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = CustomDataset('/kaggle/input/dataset/PS_8_dataset_with_followers.xlsx')  # this is a torch dataset instance\n",
    "df = pd.read_excel('/kaggle/input/dataset/PS_8_dataset_with_followers.xlsx')  # this is a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:06:30.834950Z",
     "iopub.status.busy": "2023-12-13T08:06:30.834539Z",
     "iopub.status.idle": "2023-12-13T08:06:30.839510Z",
     "shell.execute_reply": "2023-12-13T08:06:30.838735Z",
     "shell.execute_reply.started": "2023-12-13T08:06:30.834916Z"
    }
   },
   "outputs": [],
   "source": [
    "# initializing the dataloader \n",
    "dataloader = DataLoader(ds, batch_size=1, shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting likes for the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []  # all the outputs will be stored in this list \n",
    "model.eval()\n",
    "c = 0\n",
    "with torch.no_grad():\n",
    "    for data in dataloader:\n",
    "        c+=1\n",
    "        try:\n",
    "            text,mask,imgs,followers,time,is_photo,is_gif,is_video,labels = data['Text']['input_ids'],data['Text']['attention_mask'],data['img'],data['followers'],data['time'],data['is_photo'],data['is_gif'],data['is_video'],data['likes']\n",
    "            text,mask,imgs,followers,time,is_photo,is_gif,is_video,labels = text.to(device),mask.to(device),imgs.to(device),followers.to(device),time.to(device),is_photo.to(device),is_gif.to(device),is_video.to(device),labels.to(device)\n",
    "\n",
    "            output = model(text,mask,imgs,followers,time,is_photo,is_gif,is_video)\n",
    "            outputs.append(output.item())\n",
    "        except Exception as e:\n",
    "            print(data['id'])\n",
    "            print(e)\n",
    "            break\n",
    "        if c==1000:\n",
    "            print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a new column 'outputs' in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['outputs'] = outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the dataframe in the form of excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:10:19.177666Z",
     "iopub.status.busy": "2023-12-13T08:10:19.177058Z",
     "iopub.status.idle": "2023-12-13T08:10:19.217432Z",
     "shell.execute_reply": "2023-12-13T08:10:19.216110Z",
     "shell.execute_reply.started": "2023-12-13T08:10:19.177606Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_excel('submission1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4155170,
     "sourceId": 7187190,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4155177,
     "sourceId": 7187200,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4157275,
     "sourceId": 7190050,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30615,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
